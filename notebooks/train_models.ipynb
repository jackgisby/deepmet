{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Paper Analyses\n",
    "\n",
    "Replication of the analyses in the paper: TBC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from deepmet.workflows import train_single_model\n",
    "from deepmet.auxiliary import get_fingerprints_from_meta, select_features, Config\n",
    "from deepmet.datasets import load_training_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compounds were extracted from the HMDB and ZINC12 databases, subject to the following constraints:\n",
    "- Exact mass filter: 100Da < exact mass \\> 800Da\n",
    "- Other things\n",
    "\n",
    "The entire set of compounds passing these filters in HMDB were retained while a random sample of 20,000 compounds were taken from ZINC12. The smiles for these compounds are available in the `data/test_set` folder."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from shutil import copytree\n",
    "from tests.auxiliary import get_normal_non_normal_subsets\n",
    "\n",
    "# Path to write results\n",
    "results_path = os.path.join(os.path.dirname(os.path.dirname(os.path.realpath(__file__))), \"paper_results\")\n",
    "os.mkdir(results_path)\n",
    "\n",
    "# Copy input data to the results folder\n",
    "copytree(\n",
    "    os.path.join(os.path.dirname(os.path.dirname(os.path.realpath(__file__))), \"deepmet\", \"data\"),\n",
    "    os.path.join(results_path, \"data\")\n",
    ")\n",
    "\n",
    "# Location of the \"normal\" and \"non-normal\" smiles\n",
    "normal_meta_path, non_normal_meta_path = get_normal_non_normal_subsets(results_path)\n",
    "\n",
    "if not os.path.exists(results_path):\n",
    "    os.mkdir(results_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The function `train_likeness_scorer` implements the workflow for training the DeepMet model.\n",
    "For the purposes of this vignette, the individual steps will be carried out manually.\n",
    "\n",
    "While smiles are provided in the data files, these are not used as input to the model.\n",
    "If not given to the `train_likeness_scorer` function, these will be converted to molecular\n",
    "fingerprints using the smiles given as input. These are calculated in the following chunk.\n",
    "\n",
    "This is a particularly time-consuming step, so it is recommended not to unnecessarily regenerate the fingerprints."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "processed_normal_fingerprints_path = os.path.join(results_path, \"normal_fingerprints.csv\")\n",
    "processed_non_normal_fingerprints_path = os.path.join(results_path, \"non_normal_fingerprints.csv\")\n",
    "\n",
    "normal_fingerprints_path = get_fingerprints_from_meta(normal_meta_path, processed_normal_fingerprints_path)\n",
    "non_normal_fingerprints_path = get_fingerprints_from_meta(non_normal_meta_path, processed_non_normal_fingerprints_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, we set the seed and set the training options for training DeepMet. The learning rate was\n",
    "selected that was associated with the minimum loss on the validation set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Seed to be used for loading the dataset and training models\n",
    "seed = 1\n",
    "\n",
    "# Settings required by the DeepMet model\n",
    "cfg = Config({\n",
    "    \"net_name\": \"cocrystal_transformer\",\n",
    "    \"objective\": \"one-class\",\n",
    "    \"nu\": 0.1,\n",
    "    \"rep_dim\": 200,\n",
    "    \"seed\": seed,\n",
    "    \"optimizer_name\": \"amsgrad\",\n",
    "    \"lr\": 0.000155986,\n",
    "    \"n_epochs\": 20,\n",
    "    \"lr_milestones\": tuple(),\n",
    "    \"batch_size\": 2000,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"pretrain\": False,\n",
    "    \"in_features\": 2800,\n",
    "    \"device\": \"cpu\"\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "While we have now generated the molecular fingerprints, these include many poorly balanced and\n",
    "redundant features. We therefore use `select_features` to remove redundant and unbalanced features\n",
    "prior to model training.\n",
    "\n",
    "The data is then loaded into a torch-compatible format using `load_training_dataset`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "normal_fingerprints_path, non_normal_fingerprints_paths, selected_features = select_features(\n",
    "        normal_fingerprints_path=normal_fingerprints_path,\n",
    "        normal_fingerprints_out_path=os.path.join(results_path, \"selected_normal_fingerprints.csv\"),\n",
    "        non_normal_fingerprints_paths=non_normal_fingerprints_path,\n",
    "        non_normal_fingerprints_out_paths=os.path.join(results_path, \"selected_non_normal_fingerprints.csv\")\n",
    ")\n",
    "\n",
    "cfg.settings[\"selected_features\"] = selected_features\n",
    "\n",
    "# select_features allows for the simultaneous selection of multiple non-normal datasets\n",
    "# we only have a single non-normal ZINC12 set here, which we will use to evaluate the final model\n",
    "non_normal_fingerprints_path = non_normal_fingerprints_paths[0]\n",
    "\n",
    "dataset, dataset_labels, validation_dataset = load_training_dataset(\n",
    "    normal_dataset_path=normal_fingerprints_path,\n",
    "    normal_meta_path=normal_meta_path,\n",
    "    non_normal_dataset_path=non_normal_fingerprints_path,\n",
    "    non_normal_dataset_meta_path=non_normal_meta_path,\n",
    "    seed=seed,\n",
    "    validation_split=0.8,\n",
    "    test_split=0.9\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the dataset loaded, we can now train the model. The core training workflow\n",
    "is carried out using `train_single_model`. With the selected parameters, the final\n",
    "AUC on the test set is 97.91% - importantly, AUC was not used for hyperparameter\n",
    "optimisation as the validation set did not contain any \"non-normal\" compounds."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackg\\Miniconda3\\envs\\DeepMet\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "AUC on test set: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Train the model (loss is calculated on the 'normal' validation set for parameter tuning)\n",
    "deep_met_start = time.time()\n",
    "deep_met_model = train_single_model(cfg, validation_dataset)\n",
    "deep_met_end = time.time()\n",
    "\n",
    "# Test using separate test dataset (includes the ZINC12 set of 'non-normal' compounds)\n",
    "deep_met_model.test(dataset, device=\"cpu\")\n",
    "\n",
    "print(\"AUC on test set: \" + str(round(deep_met_model.results[\"test_auc\"], 4)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With DeepMet trained, we can train isolation forest and one-class SVM models for comparison. As for the DeepMet\n",
    "model, non-normal compounds are not used for parameter selection. The contamination and nu parameters were set to 0.1\n",
    "for consistency with DeepMet. The remaining isolation forest parameters and the OC-SVM kernel are the same\n",
    "as were used for the Co-crystal paper. The gamma parameter was selected using the validation set and the scaled distance of the outliers\n",
    "to the hyperplane as a loss function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pyod.models import ocsvm, iforest\n",
    "\n",
    "iforest_model = iforest.IForest(\n",
    "    contamination=0.1,\n",
    "    n_estimators=400,\n",
    "    behaviour=\"new\",\n",
    "    random_state=seed,\n",
    "    max_samples=1000\n",
    ")\n",
    "\n",
    "ocsvm_model = ocsvm.OCSVM(\n",
    "    contamination=0.1,\n",
    "    kernel=\"rbf\",\n",
    "    nu=0.1,\n",
    "    gamma=0.00386\n",
    ")\n",
    "\n",
    "x_train = validation_dataset.train_set.dataset.data[validation_dataset.train_set.indices]\n",
    "\n",
    "iforest_start = time.time()\n",
    "iforest_model.fit(x_train)\n",
    "iforest_end = time.time()\n",
    "\n",
    "ocsvm_start = time.time()\n",
    "ocsvm_model.fit(x_train)\n",
    "ocsvm_end = time.time()\n",
    "\n",
    "pickle.dump(iforest_model, open(os.path.join(results_path, \"iforest_model.pkl\"), \"wb\"))\n",
    "pickle.dump(ocsvm_model, open(os.path.join(results_path, \"ocsvm_model.pkl\"), \"wb\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The isolation forests and OC-SVM models take a long time to train relative to DeepMet."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepMet training time: 164 seconds\n",
      "Isolation forests training time: 691 seconds\n",
      "OC-SVM training time: 434 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"DeepMet training time: \" + str(round(deep_met_end - deep_met_start)) + \" seconds\")\n",
    "print(\"Isolation forests training time: \" + str(round(iforest_end - iforest_start)) + \" seconds\")\n",
    "print(\"OC-SVM training time: \" + str(round(ocsvm_end - ocsvm_start)) + \" seconds\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can calculate AUC for these models as was done for DeepMet. Both the isolation forests and the OC-SVM\n",
    "models have similar discriminative performance; they both have a lower AUC compared to DeepMet."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolation forest AUC: 0.94\n",
      "OC-SVM AUC: 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "x_test = dataset.test_set.dataset.data[dataset.test_set.indices]\n",
    "labels_test = dataset.test_set.dataset.labels[dataset.test_set.indices]\n",
    "\n",
    "print(\"Isolation forest AUC: \" + str(round(roc_auc_score(labels_test, iforest_model.decision_function(x_test)), 2)))\n",
    "print(\"OC-SVM AUC: \" + str(round(roc_auc_score(labels_test, ocsvm_model.decision_function(x_test)), 2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-fac89138",
   "language": "python",
   "display_name": "PyCharm (DeepMet)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}