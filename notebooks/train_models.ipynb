{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Paper Analyses\n",
    "\n",
    "Replication of the analyses in the paper: TBC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.append(os.path.join(\"..\", \"..\", \"DeepMet\", \"src\"))\n",
    "from workflow.training import train_single_model\n",
    "from utils.feature_processing import get_fingerprints_from_meta, select_features\n",
    "from datasets.main import load_dataset\n",
    "from utils.config import Config"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compounds were extracted from the HMDB and ZINC12 databases, subject to the following constraints:\n",
    "- Exact mass filter: 100Da < exact mass \\> 800Da\n",
    "- Other things\n",
    "\n",
    "The entire set of compounds passing these filters in HMDB were retained while a random sample of 20,000 compounds were taken from ZINC12. The smiles for these compounds are available in the `data/test_set` folder."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "data_path = \"../data/test_set/\"\n",
    "\n",
    "# Location of the \"normal\" and \"non-normal\" smiles\n",
    "normal_meta_path = os.path.join(data_path, \"hmdb_meta.csv\")\n",
    "non_normal_meta_path = os.path.join(data_path, \"zinc_meta.csv\")\n",
    "\n",
    "# Path to write results\n",
    "results_path = \"../paper_results\"\n",
    "\n",
    "if not os.path.exists(results_path):\n",
    "    os.mkdir(results_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The function `train_likeness_scorer` implements the workflow for training the DeepMet model.\n",
    "For the purposes of this vignette, the individual steps will be carried out manually.\n",
    "\n",
    "While smiles are provided in the data files, these are not used as input to the model.\n",
    "If not given to the `train_likeness_scorer` function, these will be converted to molecular\n",
    "fingerprints using the smiles given as input. These are calculated in the following chunk.\n",
    "\n",
    "This is a particularly time-consuming step, so it is recommended not to unnecessarily regenerate the fingerprints."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# normal_fingerprints_path = get_fingerprints_from_meta(normal_meta_path, os.path.join(results_path, \"normal_fingerprints.csv\"))\n",
    "# non_normal_fingerprints_path = get_fingerprints_from_meta(non_normal_meta_path, os.path.join(results_path, \"non_normal_fingerprints.csv\"))\n",
    "\n",
    "normal_fingerprints_path = os.path.join(results_path, \"normal_fingerprints.csv\")\n",
    "non_normal_fingerprints_path = os.path.join(results_path, \"non_normal_fingerprints.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, we set the seed and set the training options for training DeepMet. The learning rate was\n",
    "selected that was associated with the minimum loss on the validation set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# Seed to be used for loading the dataset and training models\n",
    "seed = 1\n",
    "\n",
    "# Settings required by the DeepMet model\n",
    "cfg = Config({\n",
    "    \"net_name\": \"cocrystal_transformer\",\n",
    "    \"objective\": \"soft-boundary\",\n",
    "    \"nu\": 0.1,\n",
    "    \"rep_dim\": 200,\n",
    "    \"seed\": seed,\n",
    "    \"optimizer_name\": \"amsgrad\",\n",
    "    \"lr\": 0.000100095,\n",
    "    \"n_epochs\": 20,\n",
    "    \"lr_milestones\": tuple(),\n",
    "    \"batch_size\": 2000,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"pretrain\": False,\n",
    "    \"in_features\": 2800,\n",
    "    \"device\": \"cpu\"\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "While we have now generated the molecular fingerprints, these include many poorly balanced and\n",
    "redundant features. We therefore use `select_features` to remove redundant and unbalanced features\n",
    "prior to model training.\n",
    "\n",
    "The data is then loaded into a torch-compatible format using `load_dataset`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-31-2fd0cf8812f0>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m normal_fingerprints_path, non_normal_fingerprints_paths = select_features(\n\u001B[0m\u001B[0;32m      2\u001B[0m         \u001B[0mnormal_fingerprints_path\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnormal_fingerprints_path\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m         \u001B[0mnormal_fingerprints_out_path\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresults_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"selected_normal_fingerprints.csv\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m         \u001B[0mnon_normal_fingerprints_paths\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnon_normal_fingerprints_path\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m         \u001B[0mnon_normal_fingerprints_out_paths\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresults_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"selected_non_normal_fingerprints.csv\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\OneDrive\\Documents\\Work\\Imperial_PhD\\Side_projects\\DeepMet\\scripting\\DeepMet\\notebooks\\..\\..\\DeepMet\\src\\utils\\feature_processing.py\u001B[0m in \u001B[0;36mselect_features\u001B[1;34m(normal_fingerprints_path, normal_fingerprints_out_path, non_normal_fingerprints_paths, non_normal_fingerprints_out_paths, unbalanced)\u001B[0m\n\u001B[0;32m     78\u001B[0m                     unbalanced=0.1):\n\u001B[0;32m     79\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 80\u001B[1;33m     \u001B[0mnormal_fingerprints\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnormal_fingerprints_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mint\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mheader\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindex_col\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     81\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     82\u001B[0m     \u001B[1;31m# Get inital dataset shape\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Miniconda3\\envs\\DeepMet\\lib\\site-packages\\pandas\\util\\_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    310\u001B[0m                 )\n\u001B[1;32m--> 311\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    312\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    313\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Miniconda3\\envs\\DeepMet\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    584\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    585\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 586\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    587\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    588\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Miniconda3\\envs\\DeepMet\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    486\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    487\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mparser\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 488\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mparser\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnrows\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    489\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    490\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Miniconda3\\envs\\DeepMet\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001B[0m in \u001B[0;36mread\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m   1045\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnrows\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1046\u001B[0m         \u001B[0mnrows\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mvalidate_integer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"nrows\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnrows\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1047\u001B[1;33m         \u001B[0mindex\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcolumns\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcol_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnrows\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1048\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1049\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mindex\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Miniconda3\\envs\\DeepMet\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001B[0m in \u001B[0;36mread\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m    221\u001B[0m         \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    222\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlow_memory\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 223\u001B[1;33m                 \u001B[0mchunks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reader\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_low_memory\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnrows\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    224\u001B[0m                 \u001B[1;31m# destructive to chunks\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    225\u001B[0m                 \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_concatenate_chunks\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mchunks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Miniconda3\\envs\\DeepMet\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m~\\Miniconda3\\envs\\DeepMet\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._read_rows\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m~\\Miniconda3\\envs\\DeepMet\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m~\\Miniconda3\\envs\\DeepMet\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m~\\Miniconda3\\envs\\DeepMet\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m~\\Miniconda3\\envs\\DeepMet\\lib\\site-packages\\pandas\\core\\dtypes\\common.py\u001B[0m in \u001B[0;36mis_extension_array_dtype\u001B[1;34m(arr_or_dtype)\u001B[0m\n\u001B[0;32m   1418\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1419\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1420\u001B[1;33m \u001B[1;32mdef\u001B[0m \u001B[0mis_extension_array_dtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marr_or_dtype\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mbool\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1421\u001B[0m     \"\"\"\n\u001B[0;32m   1422\u001B[0m     \u001B[0mCheck\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0man\u001B[0m \u001B[0mobject\u001B[0m \u001B[1;32mis\u001B[0m \u001B[0ma\u001B[0m \u001B[0mpandas\u001B[0m \u001B[0mextension\u001B[0m \u001B[0marray\u001B[0m \u001B[0mtype\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "normal_fingerprints_path, non_normal_fingerprints_paths = select_features(\n",
    "        normal_fingerprints_path=normal_fingerprints_path,\n",
    "        normal_fingerprints_out_path=os.path.join(results_path, \"selected_normal_fingerprints.csv\"),\n",
    "        non_normal_fingerprints_paths=non_normal_fingerprints_path,\n",
    "        non_normal_fingerprints_out_paths=os.path.join(results_path, \"selected_non_normal_fingerprints.csv\")\n",
    ")\n",
    "\n",
    "# select_features allows for the simultaneous selection of multiple non-normal datasets\n",
    "# we only have a single non-normal ZINC12 set here, which we will use to evaluate the final model\n",
    "non_normal_fingerprints_path = non_normal_fingerprints_paths[0]\n",
    "\n",
    "dataset, dataset_labels, validation_dataset = load_dataset(\n",
    "    normal_dataset_path=normal_fingerprints_path,\n",
    "    normal_meta_path=normal_meta_path,\n",
    "    non_normal_dataset_path=non_normal_fingerprints_path,\n",
    "    non_normal_dataset_meta_path=non_normal_meta_path,\n",
    "    seed=seed,\n",
    "    validation_split=0.8,\n",
    "    test_split=0.9\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the dataset loaded, we can now train the model. The core training workflow\n",
    "is carried out using `train_single_model`. With the selected parameters, the final\n",
    "AUC on the test set is 97.91% - importantly, AUC was not used for hyperparameter\n",
    "optimisation as the validation set did not contain any \"non-normal\" compounds."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Set seed to 1.\n",
      "INFO:root:Pretraining: False\n",
      "INFO:root:Training optimizer: amsgrad\n",
      "INFO:root:Training learning rate: 0.000100095\n",
      "INFO:root:Training epochs: 20\n",
      "INFO:root:Training batch size: 2000\n",
      "INFO:root:Training weight decay: 1e-05\n",
      "INFO:root:Initializing center c...\n",
      "INFO:root:Center c initialized.\n",
      "INFO:root:Starting training...\n",
      "C:\\Users\\jackg\\Miniconda3\\envs\\DeepMet\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "INFO:root:  Epoch 1/20\t Time: 9.282\t Loss: 73.16297208\n",
      "INFO:root:  Epoch 2/20\t Time: 10.695\t Loss: 21.90962161\n",
      "INFO:root:  Epoch 3/20\t Time: 10.243\t Loss: 13.23123330\n",
      "INFO:root:  Epoch 4/20\t Time: 9.685\t Loss: 9.89393762\n",
      "INFO:root:  Epoch 5/20\t Time: 9.972\t Loss: 8.20444940\n",
      "INFO:root:  Epoch 6/20\t Time: 9.779\t Loss: 7.13790475\n",
      "INFO:root:  Epoch 7/20\t Time: 10.058\t Loss: 6.36628474\n",
      "INFO:root:  Epoch 8/20\t Time: 9.910\t Loss: 5.76024587\n",
      "INFO:root:  Epoch 9/20\t Time: 9.228\t Loss: 5.26467004\n",
      "INFO:root:  Epoch 10/20\t Time: 9.307\t Loss: 4.85354354\n",
      "INFO:root:  Epoch 11/20\t Time: 9.817\t Loss: 1.70031831\n",
      "INFO:root:  Epoch 12/20\t Time: 9.968\t Loss: 1.39002685\n",
      "INFO:root:  Epoch 13/20\t Time: 10.045\t Loss: 1.33626748\n",
      "INFO:root:  Epoch 14/20\t Time: 10.353\t Loss: 1.29070999\n",
      "INFO:root:  Epoch 15/20\t Time: 10.708\t Loss: 1.24791936\n",
      "INFO:root:  Epoch 16/20\t Time: 10.030\t Loss: 1.20971158\n",
      "INFO:root:  Epoch 17/20\t Time: 10.006\t Loss: 1.17415335\n",
      "INFO:root:  Epoch 18/20\t Time: 9.614\t Loss: 1.14051726\n",
      "INFO:root:  Epoch 19/20\t Time: 9.560\t Loss: 1.11097981\n",
      "INFO:root:  Epoch 20/20\t Time: 9.690\t Loss: 1.08007391\n",
      "INFO:root:Training time: 197.969\n",
      "INFO:root:Finished training.\n",
      "INFO:root:Starting testing...\n",
      "INFO:root:Test set Loss: 0.45160134\n",
      "INFO:root:Testing time: 0.445\n",
      "INFO:root:Finished testing.\n",
      "INFO:root:Starting testing...\n",
      "INFO:root:Test set Loss: 1.52359285\n",
      "INFO:root:Testing time: 3.399\n",
      "INFO:root:Test set AUC: 97.91%\n",
      "INFO:root:Finished testing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only one class present in y_true. ROC AUC score is not defined in that case.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-34-f02cf75dee8f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;31m# Save model parameters\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m \u001B[0mdeep_met_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresults_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"deep_met_model.tar\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\OneDrive\\Documents\\Work\\Imperial_PhD\\Side_projects\\DeepMet\\scripting\\DeepMet\\notebooks\\..\\..\\DeepMet\\src\\deepSVDD.py\u001B[0m in \u001B[0;36msave_model\u001B[1;34m(self, export_model, save_ae)\u001B[0m\n\u001B[0;32m    146\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    147\u001B[0m         \u001B[0mnet_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnet\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstate_dict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 148\u001B[1;33m         \u001B[0mae_net_dict\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mae_net\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstate_dict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0msave_ae\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    149\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    150\u001B[0m         torch.save({'R': self.R,\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'state_dict'"
     ]
    }
   ],
   "source": [
    "# Train the model (loss is calculated on the 'normal' validation set for parameter tuning)\n",
    "deep_met_start = time.clock()\n",
    "deep_met_model = train_single_model(cfg, validation_dataset)\n",
    "deep_met_end = time.clock()\n",
    "\n",
    "# Test using separate test dataset (includes the ZINC12 set of 'non-normal' compounds)\n",
    "deep_met_model.test(dataset, device=\"cpu\")\n",
    "\n",
    "# AUC = 97.91%\n",
    "print(\"AUC on test set: \" + str(round(deep_met_model.results[\"test_auc\"], 4)))\n",
    "\n",
    "# Save model parameters\n",
    "deep_met_model.save_model(os.path.join(results_path, \"deep_met_model.tar\"), False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With DeepMet trained, we can train isolation forest and one-class SVM models for comparison. As for the DeepMet\n",
    "model, non-normal compounds are not used for parameter selection. The contamination and nu parameters were set to 0.1\n",
    "for consistency with DeepMet. The remaining isolation forest parameters and the OC-SVM kernel are the same\n",
    "as were used for the Co-crystal paper. The gamma parameter was selected using the validation set and the scaled distance of the outliers\n",
    "to the hyperplane as a loss function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pyod.models import ocsvm, iforest\n",
    "\n",
    "# iforest_model = iforest.IForest(\n",
    "#     contamination=0.1,\n",
    "#     n_estimators=400,\n",
    "#     behaviour=\"new\",\n",
    "#     random_state=seed,\n",
    "#     max_samples=1000\n",
    "# )\n",
    "\n",
    "ocsvm_model = ocsvm.OCSVM(\n",
    "    contamination=0.1,\n",
    "    kernel=\"rbf\",\n",
    "    nu=0.1,\n",
    "    gamma=0.05\n",
    ")\n",
    "\n",
    "x_train = validation_dataset.train_set.dataset.data[validation_dataset.train_set.indices]\n",
    "\n",
    "# iforest_start = time.clock()\n",
    "# iforest_model.fit(x_train)\n",
    "# iforest_end = time.clock()\n",
    "\n",
    "ocsvm_start = time.time()\n",
    "ocsvm_model.fit(x_train)\n",
    "ocsvm_end = time.time()\n",
    "\n",
    "# pickle.dump(iforest_model, open(os.path.join(results_path, \"iforest_model.pkl\"), \"wb\"))\n",
    "pickle.dump(ocsvm_model, open(os.path.join(results_path, \"ocsvm_model.pkl\"), \"wb\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The isolation forests and OC-SVM models take a long time to train relative to DeepMet."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"DeepMet training time: \" + str(deep_met_end - deep_met_start))\n",
    "print(\"Isolation forests training time: \" + str(iforest_end - iforest_start))\n",
    "print(\"OC-SVM training time: \" + str(ocsvm_end - ocsvm_start))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can calculate AUC for these models as was done for DeepMet. Both the isolation forests and the OC-SVM\n",
    "models have similar discriminative performance; they both have a lower AUC compared to DeepMet."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OC-SVM AUC: 0.99220562461156\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "x_test = dataset.test_set.dataset.data[dataset.test_set.indices]\n",
    "labels_test = dataset.test_set.dataset.labels[dataset.test_set.indices]\n",
    "\n",
    "# print(\"Isolation forest AUC: \" + str(roc_auc_score(labels_test, iforest_model.decision_function(x_test))))\n",
    "print(\"OC-SVM AUC: \" + str(roc_auc_score(labels_test, ocsvm_model.decision_function(x_test))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-fac89138",
   "language": "python",
   "display_name": "PyCharm (DeepMet)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}