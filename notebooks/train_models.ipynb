{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Model training\n",
    "\n",
    "Training a model for the one-class classification of metabolites. Replicates the training process of the associated paper, using a subset of the data: link_to_paper"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from shutil import copytree\n",
    "from pyod.models import ocsvm, iforest\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from tests.auxiliary import get_normal_non_normal_subsets\n",
    "from deepmet.auxiliary import get_fingerprints_from_meta, select_features, Config\n",
    "from deepmet.datasets import load_training_dataset\n",
    "from deepmet.workflows import train_single_model, train_likeness_scorer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compounds were extracted from the HMDB and ZINC12 databases, subject to the following constraints:\n",
    "- Exact mass filter: 100Da < exact mass \\> 800Da\n",
    "- Other things\n",
    "\n",
    "The entire set of compounds passing these filters in HMDB were retained while a random sample of 20,000 compounds were taken from ZINC12. The smiles for these compounds are available in the `data/test_set` folder."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Path to write results\n",
    "results_path = os.path.join(os.path.dirname(os.path.abspath(\"\")), \"notebook_results\")\n",
    "\n",
    "if not os.path.exists(results_path):\n",
    "    os.mkdir(results_path)\n",
    "\n",
    "# Copy input data to the results folder\n",
    "copytree(\n",
    "    os.path.join(os.path.dirname(os.path.abspath(\"\")), \"deepmet\", \"data\"),\n",
    "    os.path.join(results_path, \"data\")\n",
    ")\n",
    "\n",
    "# Seed to be used for loading the dataset and training models\n",
    "seed = 1\n",
    "\n",
    "# Location of the \"normal\" and \"non-normal\" smiles\n",
    "normal_meta_path, non_normal_meta_path = get_normal_non_normal_subsets(results_path, seed=seed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The function `train_likeness_scorer` implements the workflow for training the DeepMet model.\n",
    "For the purposes of this vignette, we will first carry out the individual steps manually.\n",
    "\n",
    "While smiles are provided in the data files, these are not used as input to the model.\n",
    "If not given to the `train_likeness_scorer` function, these will be converted to molecular\n",
    "fingerprints using the smiles given as input. These are calculated in the following chunk.\n",
    "\n",
    "This is a particularly time-consuming step, so it is recommended not to unnecessarily regenerate the fingerprints."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "processed_normal_fingerprints_path = os.path.join(results_path, \"normal_fingerprints.csv\")\n",
    "processed_non_normal_fingerprints_path = os.path.join(results_path, \"non_normal_fingerprints.csv\")\n",
    "\n",
    "normal_fingerprints_path = get_fingerprints_from_meta(normal_meta_path, processed_normal_fingerprints_path)\n",
    "non_normal_fingerprints_path = get_fingerprints_from_meta(non_normal_meta_path, processed_non_normal_fingerprints_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here, we set the seed and set the training options for training DeepMet. The learning rate was\n",
    "selected that was associated with the minimum loss on the validation set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Settings required by the DeepMet model\n",
    "cfg = Config({\n",
    "    \"net_name\": \"cocrystal_transformer\",\n",
    "    \"objective\": \"one-class\",\n",
    "    \"nu\": 0.1,\n",
    "    \"rep_dim\": 200,\n",
    "    \"seed\": seed,\n",
    "    \"optimizer_name\": \"amsgrad\",\n",
    "    \"lr\": 0.000155986,\n",
    "    \"n_epochs\": 20,\n",
    "    \"lr_milestones\": tuple(),\n",
    "    \"batch_size\": 2000,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    \"pretrain\": False,\n",
    "    \"in_features\": 2746,\n",
    "    \"device\": \"cpu\"\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "While we have now generated the molecular fingerprints, these include many poorly balanced and\n",
    "redundant features. We therefore use `select_features` to remove redundant and unbalanced features\n",
    "prior to model training.\n",
    "\n",
    "The data is then loaded into a torch-compatible format using `load_training_dataset`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "normal_fingerprints_path, non_normal_fingerprints_paths, selected_features = select_features(\n",
    "        normal_fingerprints_path=normal_fingerprints_path,\n",
    "        normal_fingerprints_out_path=os.path.join(results_path, \"selected_normal_fingerprints.csv\"),\n",
    "        non_normal_fingerprints_paths=non_normal_fingerprints_path,\n",
    "        non_normal_fingerprints_out_paths=os.path.join(results_path, \"selected_non_normal_fingerprints.csv\")\n",
    ")\n",
    "\n",
    "cfg.settings[\"selected_features\"] = selected_features\n",
    "\n",
    "# select_features allows for the simultaneous selection of multiple non-normal datasets\n",
    "# we only have a single non-normal ZINC12 set here, which we will use to evaluate the final model\n",
    "non_normal_fingerprints_path = non_normal_fingerprints_paths[0]\n",
    "\n",
    "dataset, dataset_labels, validation_dataset = load_training_dataset(\n",
    "    normal_dataset_path=normal_fingerprints_path,\n",
    "    normal_meta_path=normal_meta_path,\n",
    "    non_normal_dataset_path=non_normal_fingerprints_path,\n",
    "    non_normal_dataset_meta_path=non_normal_meta_path,\n",
    "    seed=seed,\n",
    "    validation_split=0.8,\n",
    "    test_split=0.9\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the dataset loaded, we can now train the model. The core training workflow\n",
    "is carried out using `train_single_model`. We can use AUC to evaluate the model's\n",
    "discriminative capacity for metabolites vs ZINC12 compounds - but, importantly,\n",
    "AUC is not used for hyperparameter optimisation as the validation set does not\n",
    "contain any \"non-normal\" compounds."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackg\\Miniconda3\\envs\\DeepMet\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "AUC on test set: 0.9404\n"
     ]
    }
   ],
   "source": [
    "# Train the model (loss is calculated on the 'normal' validation set for parameter tuning)\n",
    "deep_met_model = train_single_model(cfg, validation_dataset)\n",
    "\n",
    "# Test using separate test dataset (includes the ZINC12 set of 'non-normal' compounds)\n",
    "deep_met_model.test(dataset, device=cfg.settings[\"device\"])\n",
    "\n",
    "initial_auc = round(deep_met_model.results[\"test_auc\"], 4)\n",
    "print(\"AUC on test set: \" + str(initial_auc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instead of going through each of these steps, the `train_likeness_scorer`\n",
    "can train a model from scratch from the original smiles. Here, we re-train\n",
    "the model using the same settings as above and the pre-calculated fingerprints."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Log file is C:\\Users\\jackg\\OneDrive\\Documents\\Work\\Imperial_PhD\\Side_projects\\DeepMet\\scripting\\DeepMet\\notebook_results/log.txt.\n",
      "INFO:root:Export path is C:\\Users\\jackg\\OneDrive\\Documents\\Work\\Imperial_PhD\\Side_projects\\DeepMet\\scripting\\DeepMet\\notebook_results.\n",
      "INFO:root:Network: cocrystal_transformer\n",
      "INFO:root:The filtered normal fingerprint matrix path is C:\\Users\\jackg\\OneDrive\\Documents\\Work\\Imperial_PhD\\Side_projects\\DeepMet\\scripting\\DeepMet\\notebook_results\\normal_fingerprints_processed.csv.\n",
      "INFO:root:The filtered normal meta is C:\\Users\\jackg\\OneDrive\\Documents\\Work\\Imperial_PhD\\Side_projects\\DeepMet\\scripting\\DeepMet\\notebook_results\\normal_meta.csv.\n",
      "INFO:root:The filtered non-normal fingerprint matrix path is C:\\Users\\jackg\\OneDrive\\Documents\\Work\\Imperial_PhD\\Side_projects\\DeepMet\\scripting\\DeepMet\\notebook_results\\non_normal_fingerprints_processed.csv.\n",
      "INFO:root:The filtered non-normal meta is C:\\Users\\jackg\\OneDrive\\Documents\\Work\\Imperial_PhD\\Side_projects\\DeepMet\\scripting\\DeepMet\\notebook_results\\non_normal_meta.csv.\n",
      "INFO:root:Deep SVDD objective: one-class\n",
      "INFO:root:Nu-parameter: 0.10\n",
      "INFO:root:Computation device: cpu\n",
      "INFO:root:Number of input features: 2746\n",
      "INFO:root:Set seed to 1.\n",
      "INFO:root:Training optimizer: amsgrad\n",
      "INFO:root:Training learning rate: 0.000155986\n",
      "INFO:root:Training epochs: 20\n",
      "INFO:root:Training batch size: 2000\n",
      "INFO:root:Training weight decay: 1e-05\n",
      "INFO:root:Initializing center c...\n",
      "INFO:root:Center c initialized.\n",
      "INFO:root:Starting training...\n",
      "C:\\Users\\jackg\\Miniconda3\\envs\\DeepMet\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "INFO:root:  Epoch 1/20\t Time: 0.245\t Loss: 6.08613014\n",
      "INFO:root:  Epoch 2/20\t Time: 0.276\t Loss: 41.17364883\n",
      "INFO:root:  Epoch 3/20\t Time: 0.210\t Loss: 19.69269943\n",
      "INFO:root:  Epoch 4/20\t Time: 0.223\t Loss: 15.97539139\n",
      "INFO:root:  Epoch 5/20\t Time: 0.318\t Loss: 10.52810764\n",
      "INFO:root:  Epoch 6/20\t Time: 0.256\t Loss: 8.86841393\n",
      "INFO:root:  Epoch 7/20\t Time: 0.214\t Loss: 6.90053034\n",
      "INFO:root:  Epoch 8/20\t Time: 0.222\t Loss: 6.01496744\n",
      "INFO:root:  Epoch 9/20\t Time: 0.203\t Loss: 5.74058676\n",
      "INFO:root:  Epoch 10/20\t Time: 0.201\t Loss: 4.79901552\n",
      "INFO:root:  Epoch 11/20\t Time: 0.201\t Loss: 4.31278038\n",
      "INFO:root:  Epoch 12/20\t Time: 0.217\t Loss: 4.21338844\n",
      "INFO:root:  Epoch 13/20\t Time: 0.220\t Loss: 3.69345236\n",
      "INFO:root:  Epoch 14/20\t Time: 0.202\t Loss: 3.26012659\n",
      "INFO:root:  Epoch 15/20\t Time: 0.201\t Loss: 2.85929441\n",
      "INFO:root:  Epoch 16/20\t Time: 0.205\t Loss: 2.58716440\n",
      "INFO:root:  Epoch 17/20\t Time: 0.241\t Loss: 2.53407598\n",
      "INFO:root:  Epoch 18/20\t Time: 0.224\t Loss: 2.38453221\n",
      "INFO:root:  Epoch 19/20\t Time: 0.207\t Loss: 2.20460486\n",
      "INFO:root:  Epoch 20/20\t Time: 0.197\t Loss: 2.00281143\n",
      "INFO:root:Training time: 4.502\n",
      "INFO:root:Finished training.\n",
      "INFO:root:Starting testing...\n",
      "INFO:root:Test set Loss: 2.26239038\n",
      "INFO:root:Testing time: 0.010\n",
      "INFO:root:Finished testing.\n",
      "INFO:root:Starting testing...\n",
      "INFO:root:Test set Loss: 3.42835784\n",
      "INFO:root:Testing time: 0.014\n",
      "INFO:root:Test set AUC: 94.04%\n",
      "INFO:root:Finished testing.\n",
      "INFO:root:The AUC on the test dataset is: 0.9403999999999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "AUC on test set: 0.9404\n"
     ]
    }
   ],
   "source": [
    "deep_met_model = train_likeness_scorer(\n",
    "    normal_meta_path=normal_meta_path,\n",
    "    non_normal_meta_path=non_normal_meta_path,\n",
    "    normal_fingerprints_path=normal_fingerprints_path,\n",
    "    non_normal_fingerprints_path=non_normal_fingerprints_path,\n",
    "    results_path=results_path,\n",
    "    net_name=cfg.settings[\"net_name\"],\n",
    "    objective=cfg.settings[\"objective\"],\n",
    "    nu=cfg.settings[\"nu\"],\n",
    "    rep_dim=cfg.settings[\"rep_dim\"],\n",
    "    device=cfg.settings[\"device\"],\n",
    "    seed=seed,\n",
    "    optimizer_name=cfg.settings[\"optimizer_name\"],\n",
    "    lr=cfg.settings[\"lr\"],\n",
    "    n_epochs=cfg.settings[\"n_epochs\"],\n",
    "    lr_milestones=cfg.settings[\"lr_milestones\"],\n",
    "    batch_size=cfg.settings[\"batch_size\"],\n",
    "    weight_decay=cfg.settings[\"weight_decay\"],\n",
    "    validation_split=0.8,\n",
    "    test_split=0.9\n",
    ")\n",
    "\n",
    "workflow_auc = round(deep_met_model.results[\"test_auc\"], 4)\n",
    "assert initial_auc == workflow_auc\n",
    "\n",
    "print(\"AUC on test set: \" + str(workflow_auc))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With DeepMet trained, we can train isolation forest and one-class SVM models for comparison. As for the DeepMet\n",
    "model, non-normal compounds are not used for parameter selection. The contamination and nu parameters were set to 0.1\n",
    "for consistency with DeepMet. The remaining isolation forest parameters and the OC-SVM kernel are the same\n",
    "as were used for the Co-crystal paper. The gamma parameter was selected using the validation set and the scaled distance of the outliers\n",
    "to the hyperplane as a loss function."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackg\\Miniconda3\\envs\\DeepMet\\lib\\site-packages\\sklearn\\ensemble\\_iforest.py:263: UserWarning: max_samples (1000) is greater than the total number of samples (400). max_samples will be set to n_samples for estimation.\n",
      "  warn(\"max_samples (%s) is greater than the \"\n"
     ]
    }
   ],
   "source": [
    "iforest_model = iforest.IForest(\n",
    "    contamination=0.1,\n",
    "    n_estimators=400,\n",
    "    behaviour=\"new\",\n",
    "    random_state=seed,\n",
    "    max_samples=1000\n",
    ")\n",
    "\n",
    "ocsvm_model = ocsvm.OCSVM(\n",
    "    contamination=0.1,\n",
    "    kernel=\"rbf\",\n",
    "    nu=0.1,\n",
    "    gamma=0.00386\n",
    ")\n",
    "\n",
    "x_train = validation_dataset.train_set.dataset.data[validation_dataset.train_set.indices]\n",
    "\n",
    "iforest_model.fit(x_train)\n",
    "\n",
    "ocsvm_model.fit(x_train)\n",
    "\n",
    "pickle.dump(iforest_model, open(os.path.join(results_path, \"iforest_model.pkl\"), \"wb\"))\n",
    "pickle.dump(ocsvm_model, open(os.path.join(results_path, \"ocsvm_model.pkl\"), \"wb\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can calculate AUC for these models as was done for DeepMet. Both the isolation forests and the OC-SVM\n",
    "models have similar discriminative performance; they both have a lower AUC compared to DeepMet."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9492\n",
      "0.9531999999999999\n",
      "Isolation forest AUC: 0.95\n",
      "OC-SVM AUC: 0.95\n"
     ]
    }
   ],
   "source": [
    "x_test = dataset.test_set.dataset.data[dataset.test_set.indices]\n",
    "labels_test = dataset.test_set.dataset.labels[dataset.test_set.indices]\n",
    "\n",
    "print(\"Isolation forest AUC: \" + str(round(roc_auc_score(labels_test, iforest_model.decision_function(x_test)), 4)))\n",
    "print(\"OC-SVM AUC: \" + str(round(roc_auc_score(labels_test, ocsvm_model.decision_function(x_test)), 4)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-fac89138",
   "language": "python",
   "display_name": "PyCharm (DeepMet)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}